{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Import the libraries\nimport math\nimport pandas_datareader as web\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport math\nimport matplotlib.pyplot as plt\nimport keras\nimport pandas as pd\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import *\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Creating yesterday date stamp:\n\nfrom datetime import datetime, timedelta\n\nyesterday = datetime.now() - timedelta(days=1)\nyesterday_str =yesterday.strftime('%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating 6 days in the past date stamp:\n\nfrom datetime import datetime, timedelta\n\npast6days = datetime.now() - timedelta(days=6)\npast6days_str =past6days.strftime('%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"past6days_str","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating today date stamp:\n\nfrom datetime import date\ntoday = date.today()\nprint(today)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sl = ['ADBE', 'FVRR', 'GME', 'IDXX','TMO']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for ids in range(len(sl)):\n #   m =sl[ids]\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#p=[]\n#for ids in sl:\n#    print(ids)\n#    p.append(ids)\n    \n#p","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> BUILDING THE MODELs and making prediction:"},{"metadata":{"trusted":true},"cell_type":"code","source":"todaypred_allstocks =[]\nyesterdaypred_allstocks =[]\ndiff_allstocks=[]\nratio_allstocks = []\napple_quote_pred =[]\nFinal_value_allstocks=[]\n\nfor ids in range(len(sl)):\n##BUILD MODEL:\n    #Get the stock quote \n    df = web.DataReader(sl[ids], data_source='yahoo', start='2010-01-01', end=yesterday_str) \n    #Create a new dataframe with only the 'Close' column\n    data = df.filter(['Close'])\n    #Converting the dataframe to a numpy array\n    dataset = data.values\n    #Get /Compute the number of rows to train the model on\n    training_data_len = math.ceil( len(dataset) *.8) \n    #Scale the all of the data to be values between 0 and 1 \n    scaler = MinMaxScaler(feature_range=(0, 1)) \n    scaled_data = scaler.fit_transform(dataset)\n    #Create the scaled training data set \n    train_data = scaled_data[0:training_data_len  , : ]\n    #Split the data into x_train and y_train data sets\n    x_train=[]\n    y_train = []\n    for i in range(60,len(train_data)):\n        x_train.append(train_data[i-60:i,0])\n        y_train.append(train_data[i,0])\n    #Convert x_train and y_train to numpy arrays\n    x_train, y_train = np.array(x_train), np.array(y_train)\n    #Reshape the data into the shape accepted by the LSTM\n    x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n    #Build the LSTM network model\n  #  model = Sequential()\n  #  model.add(LSTM(units=50, return_sequences=True,input_shape=(x_train.shape[1],1)))\n  #  model.add(LSTM(units=50, return_sequences=False))\n  #  model.add(Dense(units=25))\n  #  model.add(Dense(units=1))\n    #Compile the model\n  #  model.compile(optimizer='adam', loss='mean_squared_error')\n    #Train the model\n  #  model.fit(x_train, y_train, batch_size=1, epochs=1)\n    \n    ##\n    model = Sequential()\n    #Adding the first LSTM layer and some Dropout regularisation\n    model.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n    model.add(Dropout(0.2))\n    # Adding a second LSTM layer and some Dropout regularisation\n    model.add(LSTM(units = 50, return_sequences = True))\n    model.add(Dropout(0.2))\n    # Adding a third LSTM layer and some Dropout regularisation\n    model.add(LSTM(units = 50, return_sequences = True))\n    model.add(Dropout(0.2))\n    # Adding a fourth LSTM layer and some Dropout regularisation\n    model.add(LSTM(units = 50))\n    model.add(Dropout(0.2))\n    # Adding the output layer\n    model.add(Dense(units = 1))\n\n    # Compiling the RNN\n    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\n    model.fit(x_train, y_train, epochs = 100, batch_size = 32)\n    ##TEST\n    #Test data set\n    test_data = scaled_data[training_data_len - 60: , : ]\n    #Create the x_test and y_test data sets\n    x_test = []\n    y_test =  dataset[training_data_len : , : ] \n    for i in range(60,len(test_data)):\n        x_test.append(test_data[i-60:i,0])\n\n    #Convert x_test to a numpy array \n    x_test = np.array(x_test)\n    #Reshape the data into the shape accepted by the LSTM\n    x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n    #Getting the models predicted price values\n    predictions = model.predict(x_test) \n    predictions = scaler.inverse_transform(predictions)#Undo scaling\n    \n\n    \n    ###BUILD PREDICTIONS 6 days ago:\n#Get the quote\n    apple_quote = web.DataReader(sl[ids], data_source='yahoo', start='2010-01-01', end=past6days_str)\n    #Create a new dataframe\n    new_df = apple_quote.filter(['Close'])\n    #Get teh last 60 day closing price \n    last_60_days = new_df[-60:].values\n    \n    #Scale the data to be values between 0 and 1\n    scaler = MinMaxScaler(feature_range=(0, 1)) \n    \n    #Converting the dataframe to a numpy array\n    dataset = new_df.values\n    scaled_data = scaler.fit_transform(dataset)\n    last_60_days_scaled = scaler.transform(last_60_days)\n    \n    #Create an empty list\n    X_test = []\n    \n    #Append teh past 60 days\n    X_test.append(last_60_days_scaled)\n    \n    #Convert the X_test data set to a numpy array\n    X_test = np.array(X_test)\n    \n    #Reshape the data\n    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n    #Get the predicted scaled price\n    pred_price = model.predict(X_test)\n    #undo the scaling \n    pred_price = scaler.inverse_transform(pred_price)\n    #print(pred_price)\n    yesterdaypred_allstocks.append(pred_price)\n    print(yesterdaypred_allstocks[ids])\n    \n    ###BUILD PREDICTIONS today:\n    #Get the quote\n    apple_quote = web.DataReader(sl[ids], data_source='yahoo', start='2010-01-01', end=today)\n    #fino al giorno prima di predizione che voglio (predizione del quattro)\n    #Create a new dataframe\n    new_df = apple_quote.filter(['Close'])\n    #Get teh last 60 day closing price \n    last_60_days = new_df[-60:].values\n    \n    #Scale the data to be values between 0 and 1\n    scaler = MinMaxScaler(feature_range=(0, 1)) \n    \n    #Converting the dataframe to a numpy array\n    dataset = new_df.values\n    scaled_data = scaler.fit_transform(dataset)\n    last_60_days_scaled = scaler.transform(last_60_days)\n    \n    #Create an empty list\n    X_test = []\n    \n    #Append teh past 60 days\n    X_test.append(last_60_days_scaled)\n    \n    #Convert the X_test data set to a numpy array\n    X_test = np.array(X_test)\n    \n    #Reshape the data\n    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n    #Get the predicted scaled price\n    pred_price = model.predict(X_test)\n    #undo the scaling \n    pred_price = scaler.inverse_transform(pred_price)\n    #print(pred_price)\n    todaypred_allstocks.append(pred_price)\n    print(todaypred_allstocks[ids])\n    diff_stock = todaypred_allstocks[ids]- yesterdaypred_allstocks[ids]\n    diff_allstocks.append(diff_stock)\n    print(diff_allstocks[ids])\n    ratio_change = (diff_stock)/todaypred_allstocks[ids]\n    ratio_allstocks.append(ratio_change)\n   # print(ratio_allstocks[ids])\n    #real_valudiff_allstocksetoday = web.DataReader(sl[ids], data_source='yahoo', start=today, end=today)\n    #real_valuetoday = real_valuetoday.filter(['Close'])\n\n   # Final_value= real_valuetoday + ratio_change*real_valuetoday\n    #Final_value_allstocks.append(Final_value)\n    #print(Final_value_allstocks[ids])\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_allstocks","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"['ADBE', 'FVRR', 'GME', 'IDXX','TMO']"},{"metadata":{"trusted":true},"cell_type":"code","source":"ratio_allstocks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratio_change","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_valuetoday = web.DataReader('AAPL', data_source='yahoo', start=today, end=today)\nreal_valuetoday","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_allstocks/200\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ha appena fatto predizione del \n#tre 101.51 \n#e del quattro 100.54","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"todaypred_allstocks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yesterdaypred_allstocks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"appl 104 107","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Get the quote\napple_quote2 = web.DataReader('AAPL', data_source='yahoo', start='2020-11-04', end='2020-11-04')\nprint(apple_quote2['Close'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"apple= 114.95  119.03\n\ntsl = 421 438\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
